{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ba549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RealSense + YOLO + PaddleOCR + GPT êµì • (í˜•ê´‘ ìƒ‰ìƒ í†µí•© ìµœì¢… ì‹œì—°ë²„ì „) ===\n",
    "import os, gc, re, cv2, torch, numpy as np, matplotlib.pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# ===========================\n",
    "#   ê¸°ë³¸ ì„¤ì •\n",
    "# ===========================\n",
    "BAG_FILE = r\"/workspace/data/gp2.bag\"\n",
    "YOLO_WEIGHTS = r\"/workspace/mk/yolo11m-seg.pt\"\n",
    "FONT_PATH = \"/workspace/nk/1_ìº¡ìŠ¤í†¤ë””ìì¸/NanumGothicCoding-Bold.ttf\"\n",
    "\n",
    "FRAME_START, FRAME_END = 0, 9999\n",
    "FRAME_INTERVAL = 5\n",
    "OCR_MAX_DISTANCE_M = 12.0\n",
    "\n",
    "COLOR_CLUSTER = (0,255,255)    # ğŸŸ¨ í´ëŸ¬ìŠ¤í„° ë°•ìŠ¤: ë…¸ë€ìƒ‰\n",
    "COLOR_WORD    = (255,0,255)    # ğŸŸ£ ë‹¨ì–´ ë°•ìŠ¤: í˜•ê´‘ í•‘í¬(ë§ˆì  íƒ€)\n",
    "COLOR_LINE    = (255,0,0)\n",
    "\n",
    "# ===========================\n",
    "#   ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# ===========================\n",
    "def light_normalize(bgr):\n",
    "    ycrcb = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    y2 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4)).apply(y)\n",
    "    return cv2.cvtColor(cv2.merge([y2, cr, cb]), cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "def enhance_contrast(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l,a,b = cv2.split(lab)\n",
    "    l = cv2.equalizeHist(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def all_preprocesses(img):\n",
    "    return [(\"ì›ë³¸\", img), (\"ë°ê¸°ì •ê·œí™”\", light_normalize(img)), (\"ëŒ€ë¹„ê°•í™”\", enhance_contrast(img))]\n",
    "\n",
    "def similar(a,b):\n",
    "    ratio = SequenceMatcher(None,a,b).ratio()\n",
    "    if abs(len(a)-len(b)) > max(len(a),len(b))*0.5:\n",
    "        return False\n",
    "    return ratio > 0.9\n",
    "\n",
    "# ===========================\n",
    "#   ë°©í–¥ ë° ì¶”ì²œê²½ë¡œ\n",
    "# ===========================\n",
    "def direction_from_bbox(x_center, w):\n",
    "    if x_center < w/3: return \"ì™¼ìª½\"\n",
    "    elif x_center < 2*w/3: return \"ì•ìª½\"\n",
    "    else: return \"ì˜¤ë¥¸ìª½\"\n",
    "\n",
    "def recommend_path(obstacles):\n",
    "    if not obstacles: return \"ì§ì§„\"\n",
    "    left  = any(o==\"ì™¼ìª½\" for o in obstacles)\n",
    "    right = any(o==\"ì˜¤ë¥¸ìª½\" for o in obstacles)\n",
    "    front = any(o==\"ì•ìª½\" for o in obstacles)\n",
    "    if front and not left: return \"ì¢ŒíšŒì „\"\n",
    "    elif front and not right: return \"ìš°íšŒì „\"\n",
    "    elif left and not right: return \"ìš°íšŒì „\"\n",
    "    elif right and not left: return \"ì¢ŒíšŒì „\"\n",
    "    else: return \"ì§ì§„\"\n",
    "\n",
    "# ===========================\n",
    "#   GPT êµì • í•¨ìˆ˜\n",
    "# ===========================\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "def correct_text_with_api(sentence, distance, direction):\n",
    "    prompt = f\"\"\"\n",
    "    ì•„ë˜ ë¬¸ì¥ì€ OCR ì¸ì‹ ê²°ê³¼ì…ë‹ˆë‹¤. ì˜¤íƒ€ë‚˜ ë¹„ë¬¸ì„ êµì •í•˜ê³ ,\n",
    "    ìì—°ìŠ¤ëŸ¬ìš´ ì•ˆë‚´ë©˜íŠ¸ í˜•ì‹ìœ¼ë¡œ ì™„ì„±í•´ ì£¼ì„¸ìš”:\n",
    "    \"{direction} {distance:.1f}ë¯¸í„° ê±°ë¦¬ì— '{{êµì •ëœ ë¬¸ì¥}}' í‘œì§€íŒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "    OCR ë¬¸ì¥: \"{sentence}\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.responses.create(model=\"gpt-5-mini\", input=prompt)\n",
    "        return response.output_text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Lexicon ë³´ì • ì‹¤íŒ¨:\", e)\n",
    "        return f\"{direction} {distance:.1f}ë¯¸í„° ê±°ë¦¬ì— \\\"{sentence}\\\" í‘œì§€íŒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ===========================\n",
    "#   ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# ===========================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = YOLO(YOLO_WEIGHTS, task=\"segment\").to(device)\n",
    "ocr = PaddleOCR(lang=\"korean\", use_angle_cls=True, show_log=False)\n",
    "\n",
    "# ===========================\n",
    "#   RealSense ì´ˆê¸°í™”\n",
    "# ===========================\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_device_from_file(BAG_FILE, repeat_playback=False)\n",
    "config.enable_stream(rs.stream.depth, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, rs.format.rgb8, 30)\n",
    "profile = pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    pb = profile.get_device().as_playback()\n",
    "    pb.set_real_time(False)\n",
    "    print(\"âœ… RealSense playback set to non-real-time mode.\")\n",
    "except: pass\n",
    "\n",
    "# ===========================\n",
    "#   ë©”ì¸ ë£¨í”„\n",
    "# ===========================\n",
    "frame_count = 0\n",
    "\n",
    "try:\n",
    "    plt.ioff()\n",
    "    while True:\n",
    "        try:\n",
    "            frames = pipeline.wait_for_frames(timeout_ms=15000)\n",
    "        except RuntimeError:\n",
    "            print(\"âš ï¸ No more frames (end of bag or timeout).\")\n",
    "            break\n",
    "\n",
    "        aligned = align.process(frames)\n",
    "        dframe, cframe = aligned.get_depth_frame(), aligned.get_color_frame()\n",
    "        if not dframe or not cframe:\n",
    "            continue\n",
    "\n",
    "        if frame_count < FRAME_START:\n",
    "            frame_count += 1; continue\n",
    "        if frame_count > FRAME_END: break\n",
    "        if frame_count % FRAME_INTERVAL != 0:\n",
    "            frame_count += 1; continue\n",
    "\n",
    "        rgb = np.asanyarray(cframe.get_data())\n",
    "        color = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "        depth = np.asanyarray(dframe.get_data()) * depth_scale\n",
    "        h0, w0 = color.shape[:2]\n",
    "\n",
    "        # === (1) OCR ë‹¤ì¤‘ ì „ì²˜ë¦¬ í›„ í†µí•© ===\n",
    "        candidates=[]\n",
    "        for _,proc in all_preprocesses(color):\n",
    "            ocr_res = ocr.ocr(proc, det=True, rec=True, cls=False)\n",
    "            if not ocr_res: continue\n",
    "            for line in ocr_res[0]:\n",
    "                box,(txt,conf)=line\n",
    "                txt=re.sub(r'[^ê°€-í£0-9a-zA-Z ]','',txt.strip())\n",
    "                if not txt or conf<0.75: continue\n",
    "                candidates.append((txt,conf,box))\n",
    "\n",
    "        # === (2) ìœ ì‚¬ ë‹¨ì–´ ë³‘í•© ===\n",
    "        merged=[]\n",
    "        for txt,conf,box in candidates:\n",
    "            found=False\n",
    "            for m in merged:\n",
    "                if similar(txt,m[\"txt\"]):\n",
    "                    if conf>m[\"conf\"]: m.update({\"txt\":txt,\"conf\":conf,\"box\":box})\n",
    "                    found=True; break\n",
    "            if not found: merged.append({\"txt\":txt,\"conf\":conf,\"box\":box})\n",
    "\n",
    "        if not merged:\n",
    "            frame_count+=1; continue\n",
    "\n",
    "        # === (3) OCR ë‹¨ì–´ ë°•ìŠ¤ í‘œì‹œ (í˜•ê´‘ í•‘í¬) ===\n",
    "        for txt, conf, box in candidates:\n",
    "            pts = np.array(box).astype(int)\n",
    "            cv2.polylines(color, [pts], isClosed=True, color=COLOR_WORD, thickness=2)\n",
    "\n",
    "        # === (4) DBSCAN ë¬¸ì¥ í´ëŸ¬ìŠ¤í„°ë§ ===\n",
    "        eps_candidates = [int(w0 * e) for e in [0.02,0.03,0.04,0.05]]\n",
    "        best_eps, best_sil = None, -1\n",
    "        centers = np.array([[np.mean(np.array(m[\"box\"])[:,0]),\n",
    "                             np.mean(np.array(m[\"box\"])[:,1])] for m in merged])\n",
    "\n",
    "        for eps_val in eps_candidates:\n",
    "            clustering = DBSCAN(eps=eps_val, min_samples=1).fit(centers)\n",
    "            if len(set(clustering.labels_)) > 1:\n",
    "                try:\n",
    "                    sil = silhouette_score(centers, clustering.labels_)\n",
    "                    if sil > best_sil:\n",
    "                        best_sil = sil\n",
    "                        best_eps = eps_val\n",
    "                except: continue\n",
    "\n",
    "        eps_val = best_eps or int(w0 * 0.03)\n",
    "        clustering = DBSCAN(eps=eps_val, min_samples=1).fit(centers)\n",
    "        labels = clustering.labels_\n",
    "\n",
    "        clusters=[]\n",
    "        for l in set(labels):\n",
    "            group=[merged[i] for i in range(len(merged)) if labels[i]==l]\n",
    "            group.sort(key=lambda x: np.mean(np.array(x[\"box\"])[:,0]))\n",
    "            sentence=\" \".join([g[\"txt\"] for g in group])\n",
    "            conf=np.mean([g[\"conf\"] for g in group])\n",
    "            all_pts=np.concatenate([np.array(g[\"box\"]) for g in group],axis=0)\n",
    "            x1,y1=np.min(all_pts,axis=0)\n",
    "            x2,y2=np.max(all_pts,axis=0)\n",
    "            clusters.append({\"text\":sentence,\"conf\":conf,\"bbox\":[x1,y1,x2,y2]})\n",
    "\n",
    "        # === (5) GPT êµì • + ëª¨ë“  í´ëŸ¬ìŠ¤í„° í‘œì‹œ ===\n",
    "        frame_clusters = []\n",
    "        warning_detected = False\n",
    "        for cl in clusters:\n",
    "            x1,y1,x2,y2=map(int,cl[\"bbox\"])\n",
    "            txt,conf=cl[\"text\"],cl[\"conf\"]\n",
    "            cx=(x1+x2)/2\n",
    "            direction=direction_from_bbox(cx,w0)\n",
    "            roi=depth[y1:y2,x1:x2]\n",
    "            vals=roi[(roi>0)&np.isfinite(roi)]\n",
    "            if vals.size==0: continue\n",
    "            dist=float(np.median(vals))\n",
    "            if dist>OCR_MAX_DISTANCE_M: continue\n",
    "\n",
    "            corrected = correct_text_with_api(txt,dist,direction)\n",
    "            frame_clusters.append((txt, corrected, conf))\n",
    "            cv2.rectangle(color,(x1,y1),(x2,y2),COLOR_CLUSTER,3)\n",
    "\n",
    "            if any(w in txt or w in corrected for w in [\"ì£¼ì˜\",\"ìœ„í—˜\",\"ê²½ê³ \",\"ë‚™í•˜\"]):\n",
    "                warning_detected = True\n",
    "\n",
    "        # === (6) YOLO + ì¶”ì²œê²½ë¡œ ===\n",
    "        results=model.track(color,tracker=\"bytetrack.yaml\",persist=True,conf=0.25)[0]\n",
    "        boxes,ids=[],[]\n",
    "        if getattr(results,\"boxes\",None) and results.boxes.id is not None:\n",
    "            boxes=results.boxes.data.cpu().numpy()\n",
    "            ids=results.boxes.id.cpu().numpy().astype(int)\n",
    "        obstacle_dirs=[]\n",
    "        for i in range(len(ids)):\n",
    "            x_center=(boxes[i][0]+boxes[i][2])/2\n",
    "            obstacle_dirs.append(direction_from_bbox(x_center,w0))\n",
    "\n",
    "        path=recommend_path(obstacle_dirs) or \"ì§ì§„\"\n",
    "        if warning_detected:\n",
    "            path = \"ì£¼ì˜\"\n",
    "\n",
    "        # === (7) 3ë¶„í•  + ì¶”ì²œê²½ë¡œ í‘œì‹œ ===\n",
    "        h,w,_=color.shape\n",
    "        cv2.line(color,(w//3,0),(w//3,h),COLOR_LINE,2)\n",
    "        cv2.line(color,(2*w//3,0),(2*w//3,h),COLOR_LINE,2)\n",
    "\n",
    "        # === (8) í•˜ë‹¨ í…ìŠ¤íŠ¸ í‘œì‹œ ===\n",
    "        img_pil = Image.fromarray(color)\n",
    "        draw = ImageDraw.Draw(img_pil)\n",
    "        font = ImageFont.truetype(FONT_PATH, 24)\n",
    "        font_title = ImageFont.truetype(FONT_PATH, 32)\n",
    "        font_label = ImageFont.truetype(FONT_PATH, 24)\n",
    "\n",
    "        line_height = 55\n",
    "        y_text = h0 - (line_height * len(frame_clusters)) - 20\n",
    "\n",
    "        for i, (txt, corr, conf) in enumerate(frame_clusters):\n",
    "            draw.text((25, y_text + i*line_height),     f\"êµì •ë¬¸: {corr}\", font=font, fill=(255,255,0,255))\n",
    "            draw.text((25, y_text + i*line_height + 25), f\"ì›ë¬¸: {txt}\", font=font, fill=(100,200,255,255))\n",
    "\n",
    "        # ğŸŸ¡ ì¶”ì²œ ê²½ë¡œ = í´ëŸ¬ìŠ¤í„° ë°•ìŠ¤ì™€ ë™ì¼í•œ ë…¸ë€ìƒ‰\n",
    "        draw.text((20, 20), f\"ì¶”ì²œ ê²½ë¡œ: {path}\", font=font_title, fill=(0,255,255,255))\n",
    "\n",
    "        # ğŸŸ§ ì¢Œ/ì •ë©´/ìš° = í˜•ê´‘ ì£¼í™©ìƒ‰\n",
    "        ORANGE = (255,165,0,255)\n",
    "        draw.text((w//6 - 40, 10), \"ì¢Œ\", font=font_label, fill=ORANGE)\n",
    "        draw.text((w//2 - 40, 10), \"ì •ë©´\", font=font_label, fill=ORANGE)\n",
    "        draw.text((5*w//6 - 40, 10), \"ìš°\", font=font_label, fill=ORANGE)\n",
    "\n",
    "        color = np.array(img_pil)\n",
    "\n",
    "        # === ì‹œê°í™” ===\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.imshow(cv2.cvtColor(color,cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Frame {frame_count}\")\n",
    "        plt.axis(\"off\"); plt.show()\n",
    "\n",
    "        frame_count+=1\n",
    "        gc.collect()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ì¤‘ë‹¨ë¨\")\n",
    "finally:\n",
    "    try: pipeline.stop()\n",
    "    except: pass\n",
    "    gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
